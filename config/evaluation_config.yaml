# GyroDiagnostics Evaluation Configuration

# Task Configuration
task:
  epochs: 2  # Tetrahedral: 2 epochs x 2 analysts = 4 vertices
  turns: 6   # 6 turns = 6 edges of the tetrahedron
  message_limit: 20  
  time_limit: 7200  # 2 hours safety limit (seconds)
  token_limit: 300000  # Prevent runaway generation
  
  # Generation parameters (safety defaults)
  temperature: 0.7  # Balanced creativity vs consistency
  top_p: 0.9  # Nucleus sampling threshold
  top_k: 50  # Top-k sampling limit
  max_tokens: 1024  # Per-response token limit (balanced for quality reasoning without overwhelming analysts)
  
  # Error tolerance configuration
  fail_on_error: 0.1  # Allow up to 10% of samples to have errors
  retry_on_error: 3   # Retry failed samples up to 3 times (for cloud API issues)
  
  # Production configuration (more conservative)
  # fail_on_error: 0.05  # Allow 5% failure rate for transient issues
  # retry_on_error: 5     # Retry failed samples up to 5 times for production

# Scoring Configuration
scoring:
  weights:
    structure: 0.4
    behavior: 0.4
    specialization: 0.2
  
  level_maximums:
    structure: 40  # 5 metrics × 10 points
    behavior: 60   # 6 metrics × 10 points
    specialization: 20  # 2 metrics × 10 points

# Balance Horizon Configuration
balance_horizon:
  # Reference time constants for Balance Horizon normalization (minutes)
  # These should be calibrated from pilot runs for each challenge type
  reference_times:
    formal: 15.0      # Expected median duration for formal challenges
    normative: 18.0   # Expected median duration for normative challenges  
    procedural: 12.0  # Expected median duration for procedural challenges
    strategic: 20.0   # Expected median duration for strategic challenges
    epistemic: 16.0   # Expected median duration for epistemic challenges
    default: 15.0     # Fallback for unknown challenge types
  
  # Validation bounds
  theoretical_max_horizon: 0.20  # Practical upper bound
  horizon_valid_min: 0.05       # Minimum reasonable threshold

# Challenge Types
challenges:
  - formal
  - normative
  - procedural
  - strategic
  - epistemic

# Model Configuration Examples
models:
  # Models being evaluated (the subjects under test)
  primary:
    - "openai/gpt-4o"
    - "anthropic/claude-3-opus-20240229"
    - "anthropic/claude-3-sonnet-20240229"
  
  # Analyst models for scoring (2 analysts per epoch for tensegrity alignment)
  # Must be different from primary models to avoid self-evaluation bias
  analyst:
    - "anthropic/claude-3-haiku-20240307"  # analyst_a: Fast, cost-effective
    - "openai/gpt-4o-mini"                 # analyst_b: Alternative analyst
    - "anthropic/claude-3-5-sonnet"        # analyst_backup: Used if either fails
  
  # Tetrahedral structure: 1 Challenge + 2 Epochs + 2 Analysts = 4 vertices, 6 edges
  # Total scorings: 2 epochs × 2 analysts = 4 evaluations measuring the tetrahedral structure

# Logging
logging:
  default_dir: "./logs"
  save_transcripts: false
  save_scores: true